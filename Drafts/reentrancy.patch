diff --git a/CuteNotes.txt b/CuteNotes.txt
index 94ca992..0dcec91 100644
--- a/CuteNotes.txt
+++ b/CuteNotes.txt
@@ -29,6 +29,7 @@ TOC:
 (21) The Zone!
 (22) Debugging periodic timers using statistical data
 (23) The Naughty Multiply
+(24) On Reentrancy and Thread-safety
 
 
 On Intel Documents:
@@ -3011,3 +3012,93 @@ The Naughty Multiply:
   the side effects of __every__ opcode used in the kernel inlined
   assembly snippets. That's how I caught the %rflags, %rcx, and %rsi
   cases mentioned in the above point!
+
+
+On Reentrancy and Thread-safety:
+--------------------------------
+
+* Reentrancy is a super-set of thread-safety. For example, our spin
+  lock code should not be only thread-safe, but also re-entrant:
+
+  void spin_lock(struct lock_spin *lock)
+  {
+	current->rflags = local_irq_disable_save();
+
+	while (atomic_bit_test_and_set(&lock->val) == _SPIN_LOCKED) {
+		local_irq_restore(current->rflags);
+
+		while (lock->val == _SPIN_LOCKED)
+			cpu_pause();
+
+		local_irq_disable();
+	}
+  }
+
+  The above spin lock code is thread-safe. 'current' is a per-CPU
+  variable representing the process descriptor of the thread
+  'currently' executing on that CPU.
+
+  In that sense, there's a 'current->rflags' for each CPU and we
+  should be safe????
+
+  No, If an interrupt got griggered while spinning above, above
+  code will get executed in a re-entrant fashion. MUTING OLDER
+  current->rflags VALUE IN THE PROCESS!
+
+  In fact, the above code was directly responsible for a kernel
+  bug that made the kernel indefinitely disable kernel interrupts.
+
+  Here was the process:
+
+  Several CPUs called malloc() concurrently. This made the bootstrap
+  core spin for a while.
+
+  While the BSC spinning, a keyboard interrupt was triggered.
+
+  Since IRQs was on while spinning, the keyboard handler got executed.
+  Since we're using x86 "interrupt gates", IF=0 while handlers got
+  executed.
+
+  The keyboard interrupt handler issued a call to spin_lock (VGA
+  screen lock). That new call to spin_lock() was thus called with
+  interrupts disabled.
+
+  So, the new call set current->rflags with a value making IF=0;
+
+  After unlocking, and finishing the keyboard handler, the BSC malloc()
+  lock resumed spinning.
+
+  When restoring RFLAGS, malloc()'s spin_unlock() restored the one
+  with IF=0 .. leading to permanently disable bootstrap interrupts
+  and HALTING THE ENTIRE SYSTEM IN THE PROCESS.
+
+  THE SOLUTION:
+  #$#@#$@#$@#$#
+
+  Stack storage is the most reentrant-safe place possible. Use the
+  stack to save rflags.
+
+  Thus, if IF=1 before spin_lock(), busy loop while IF=1
+  if IF=0, busy loop while IF=0
+  Restore IF state at spin_unlock() by saving IF state at lock->rflags
+  AFTER acquiring the lock (Spin locks, ironically enough, are globals)
+
+* Another case functions called by IRQ handlers. They need to be
+  reentrant, not only thread safe.
+
+  Example:
+
+  CPU#1:
+  func1() -----.			  *----------------- func1() end
+	       | IRQ                      ^
+	       v 			  | IRQ end
+	       *--- handler -> func1() ---.
+
+  CPU#2:
+  func1() ---------------------- func1() end
+
+  Per-CPU variables can be enough if func1() was not called in an interrupt
+  handler, as long as preemption was disabled. Now since func1() get called
+  in IRQ context, it needs to protect its non-reentrant parts by disabling
+  interrupts (If only per-CPU vars where used), or by spinlocks that
+  disable interrupts (If globals were also used).
